import torch.nn as nn
import torch
import torch.nn.functional as F

class RoleParameterDecoder(nn.Module):
    """Role parameter decoder that transforms role embeddings into Q-network weight parameters"""
    def __init__(self, args):
        super(RoleParameterDecoder, self).__init__()
        self.role_embedding_dim = args.role_embedding_dim
        self.latent_dim = args.latent_dim  # New parameter for latent space dimension
        self.rnn_hidden_dim = args.rnn_hidden_dim
        self.n_actions = args.action_dim
        
        # Latent space transformation network
        self.latent_net = nn.Sequential(
            nn.Linear(self.role_embedding_dim, self.latent_dim),
            nn.BatchNorm1d(self.latent_dim),
            nn.LeakyReLU(inplace=True)
        )
        
        # Weight generation branch
        self.fc2_w_nn = nn.Sequential(
            nn.Linear(self.latent_dim, self.rnn_hidden_dim * self.n_actions),
            nn.BatchNorm1d(self.rnn_hidden_dim * self.n_actions),
            nn.LeakyReLU(inplace=True)
        )
        
        # Bias generation branch
        self.fc2_b_nn = nn.Sequential(
            nn.Linear(self.latent_dim, self.n_actions),
            nn.BatchNorm1d(self.n_actions),
            nn.LeakyReLU(inplace=True)
        )

    def forward(self, role_embedding):
        """
        Input: role_embedding [batch_size, role_embedding_dim]
        Output: fc2_weight [batch_size, rnn_hidden_dim, n_actions], 
                fc2_bias [batch_size, 1, n_actions]
        """
        # Transform to latent space
        latent_para = self.latent_net(role_embedding)
        
        # Generate weight parameters
        fc2_w = self.fc2_w_nn(latent_para)
        fc2_w = fc2_w.reshape(-1, self.rnn_hidden_dim, self.n_actions)
        
        # Generate bias parameters
        fc2_b = self.fc2_b_nn(latent_para)
        fc2_b = fc2_b.reshape(-1, 1, self.n_actions)  # For broadcasting compatibility
        
        return fc2_w, fc2_b

class Q_network_RNN_RoleAware(nn.Module):
    """Role-aware Q-network that uses role-generated weight parameters"""
    def __init__(self, args, input_dim):
        super(Q_network_RNN_RoleAware, self).__init__()
        self.rnn_hidden = None
        self.args = args

        # Fixed first layer parameters
        self.fc1 = nn.Linear(input_dim, args.rnn_hidden_dim)
        
        # RNN layer
        self.rnn = nn.GRUCell(args.rnn_hidden_dim, args.rnn_hidden_dim)
        
        # Second layer weights will be dynamically generated by role parameter decoder
        # No longer using fixed fc2 layer

    def forward(self, inputs, role_fc2_w, role_fc2_b):
        """
        Args:
            inputs: [batch_size, input_dim]
            role_fc2_w: [batch_size, rnn_hidden_dim, n_actions] role-generated weights
            role_fc2_b: [batch_size, 1, n_actions] role-generated biases
        Returns:
            Q: [batch_size, n_actions] action values
        """
        x = F.relu(self.fc1(inputs))
        self.rnn_hidden = self.rnn(x, self.rnn_hidden)
        
        # Compute Q-values using role-generated parameters
        # rnn_hidden: [batch_size, rnn_hidden_dim]
        # role_fc2_w: [batch_size, rnn_hidden_dim, n_actions]
        # role_fc2_b: [batch_size, 1, n_actions]
        
        # Expand dimensions for matrix multiplication
        hidden_expanded = self.rnn_hidden.unsqueeze(1)  # [batch_size, 1, rnn_hidden_dim]
        
        # Compute Q-values: [batch_size, 1, rnn_hidden_dim] @ [batch_size, rnn_hidden_dim, n_actions] 
        # = [batch_size, 1, n_actions]
        Q = torch.bmm(hidden_expanded, role_fc2_w) + role_fc2_b
        Q = Q.squeeze(1)  # [batch_size, n_actions]
        
        return Q

class Q_network_MLP_RoleAware(nn.Module):
    """Role-aware MLP Q-network with dynamically generated final layer parameters"""
    def __init__(self, args, input_dim):
        super(Q_network_MLP_RoleAware, self).__init__()
        self.args = args

        # Fixed first and second layer parameters
        self.fc1 = nn.Linear(input_dim, args.mlp_hidden_dim)
        self.fc2 = nn.Linear(args.mlp_hidden_dim, args.mlp_hidden_dim)
        
        # Third layer weights will be dynamically generated by role parameter decoder

    def forward(self, inputs, role_fc3_w, role_fc3_b):
        """
        Args:
            inputs: [batch_size, input_dim]
            role_fc3_w: [batch_size, mlp_hidden_dim, n_actions] role-generated weights
            role_fc3_b: [batch_size, 1, n_actions] role-generated biases
        Returns:
            Q: [batch_size, n_actions] action values
        """
        x = F.relu(self.fc1(inputs))
        x = F.relu(self.fc2(x))
        
        # Compute Q-values using role-generated parameters
        x_expanded = x.unsqueeze(1)  # [batch_size, 1, mlp_hidden_dim]
        Q = torch.bmm(x_expanded, role_fc3_w) + role_fc3_b
        Q = Q.squeeze(1)  # [batch_size, n_actions]
        
        return Q

class Role_Embedding_WithDecoder(nn.Module):
    """Enhanced role embedding module with integrated parameter decoder"""
    def __init__(self, args):
        super(Role_Embedding_WithDecoder, self).__init__()
        self.agent_embedding_dim = args.agent_embedding_dim
        self.role_embedding_dim = args.role_embedding_dim
        self.use_ln = args.use_ln

        # Role embedding layer
        if self.use_ln:
            self.role_embedding = nn.ModuleList([
                nn.Linear(self.agent_embedding_dim, self.role_embedding_dim),
                nn.LayerNorm(self.role_embedding_dim)
            ])
        else:
            self.role_embedding = nn.Linear(self.agent_embedding_dim, self.role_embedding_dim)
        
        # Role parameter decoder
        self.parameter_decoder = RoleParameterDecoder(args)
    
    def forward(self, agent_embedding, detach=False):
        """
        Generate role embeddings and corresponding Q-network parameters
        
        Args:
            agent_embedding: [batch_size, agent_embedding_dim] agent representation
            detach: whether to detach gradients
        Returns:
            role_emb: [batch_size, role_embedding_dim] role embeddings
            fc2_w: [batch_size, rnn_hidden_dim, n_actions] generated weights
            fc2_b: [batch_size, 1, n_actions] generated biases
        """
        # Generate role embeddings
        if self.use_ln:
            role_emb = self.role_embedding[1](self.role_embedding[0](agent_embedding))
        else:
            role_emb = self.role_embedding(agent_embedding)
        
        role_emb = torch.sigmoid(role_emb)
        
        if detach:
            role_emb = role_emb.detach()
        
        # Generate Q-network parameters through decoder
        fc2_w, fc2_b = self.parameter_decoder(role_emb)
        
        return role_emb, fc2_w, fc2_b

# Original modules with English comments
class Q_network_RNN(nn.Module):
    """RNN-based Q-network for trajectory-aware value estimation"""
    def __init__(self, args, input_dim):
        super(Q_network_RNN, self).__init__()
        self.rnn_hidden = None

        self.fc1 = nn.Linear(input_dim, args.rnn_hidden_dim)
        self.rnn = nn.GRUCell(args.rnn_hidden_dim, args.rnn_hidden_dim)
        self.fc2 = nn.Linear(args.rnn_hidden_dim, args.action_dim)

    def forward(self, inputs):
        """Forward pass through RNN Q-network"""
        x = F.relu(self.fc1(inputs))
        self.rnn_hidden = self.rnn(x, self.rnn_hidden)
        Q = self.fc2(self.rnn_hidden)
        return Q

class Q_network_MLP(nn.Module):
    """MLP-based Q-network for value estimation"""
    def __init__(self, args, input_dim):
        super(Q_network_MLP, self).__init__()
        self.rnn_hidden = None

        self.fc1 = nn.Linear(input_dim, args.mlp_hidden_dim)
        self.fc2 = nn.Linear(args.mlp_hidden_dim, args.mlp_hidden_dim)
        self.fc3 = nn.Linear(args.mlp_hidden_dim, args.action_dim)

    def forward(self, inputs):
        """Forward pass through MLP Q-network"""
        x = F.relu(self.fc1(inputs))
        x = F.relu(self.fc2(x))
        Q = self.fc3(x)
        return Q

class Agent_Embedding(nn.Module):
    """Agent embedding module for learning agent representations"""
    def __init__(self, args):
        super(Agent_Embedding, self).__init__()
        self.input_dim = args.obs_dim + args.action_dim
        self.agent_embedding_dim = args.agent_embedding_dim

        self.fc1 = nn.Linear(self.input_dim, self.agent_embedding_dim)
        self.rnn_hidden = None
        self.agent_embedding_fc = nn.GRUCell(self.agent_embedding_dim, self.agent_embedding_dim)
        self.fc2 = nn.Linear(self.agent_embedding_dim, self.agent_embedding_dim)

    def forward(self, obs, last_a, detach=False):
        """
        Generate agent embedding from observation and last action
        
        Args:
            obs: current observation
            last_a: last action taken
            detach: whether to detach gradients
        Returns:
            agent embedding representation
        """
        inputs = torch.cat([obs, last_a], dim=-1)
        fc1_out = torch.relu(self.fc1(inputs))
        self.rnn_hidden = self.agent_embedding_fc(fc1_out, self.rnn_hidden)
        fc2_out = self.fc2(self.rnn_hidden)
        if detach:
            fc2_out = fc2_out.detach()
        return fc2_out

class Agent_Embedding_Decoder(nn.Module):
    """Decoder for reconstructing agent state from embedding"""
    def __init__(self, args):
        super(Agent_Embedding_Decoder, self).__init__()
        self.agent_embedding_dim = args.agent_embedding_dim
        self.decoder_out_dim = args.obs_dim + args.N  # Output: o(t+1) + agent_idx
        
        self.fc1 = nn.Linear(self.agent_embedding_dim, self.agent_embedding_dim)
        self.fc2 = nn.Linear(self.agent_embedding_dim, self.decoder_out_dim)

    def forward(self, agent_embedding):
        """Decode agent embedding to reconstruct next observation and agent index"""
        fc1_out = torch.relu(self.fc1(agent_embedding))
        decoder_out = self.fc2(fc1_out)
        return decoder_out

class Role_Embedding(nn.Module):
    """Role embedding module for learning role representations"""
    def __init__(self, args):
        super(Role_Embedding, self).__init__()
        self.agent_embedding_dim = args.agent_embedding_dim
        self.role_embedding_dim = args.role_embedding_dim
        self.use_ln = args.use_ln

        if self.use_ln:     # Use layer normalization
            self.role_embeding = nn.ModuleList([nn.Linear(self.agent_embedding_dim, self.role_embedding_dim),
                                                nn.LayerNorm(self.role_embedding_dim)])
        else:
            self.role_embeding = nn.Linear(self.agent_embedding_dim, self.role_embedding_dim)
    
    def forward(self, agent_embedding, detach=False):
        """Generate role embedding from agent embedding"""
        if self.use_ln:
            output = self.role_embeding[1](self.role_embeding[0](agent_embedding))
        else:
            output = self.role_embeding(agent_embedding)
        
        if detach:
            output = output.detach()
        output = torch.sigmoid(output)
        return output

# Training framework example with English comments
class TrainingFramework:
    """Example training framework demonstrating the integrated architecture"""
    def __init__(self, args):
        self.args = args
        self.agent_embedding = Agent_Embedding(args)
        self.role_embedding = Role_Embedding_WithDecoder(args)
        self.q_network = Q_network_RNN_RoleAware(args, args.obs_dim)
        
    def compute_q_values(self, obs, last_actions):
        """
        Compute Q-values using role-aware architecture
        
        Args:
            obs: current observations
            last_actions: last actions taken
        Returns:
            q_values: computed action values
            role_emb: role embeddings for analysis
        """
        # Generate agent embedding
        agent_emb = self.agent_embedding(obs, last_actions)
        
        # Generate role embedding and Q-network parameters
        role_emb, fc2_w, fc2_b = self.role_embedding(agent_emb)
        
        # Compute Q-values using role-specific parameters
        q_values = self.q_network(obs, fc2_w, fc2_b)
        
        return q_values, role_emb